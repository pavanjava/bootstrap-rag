#!/bin/sh
# Pull the llama3.1 model using Ollama

# Pull the model without running it
ollama pull llama3.1
ollama pull nomic-embed-text:latest